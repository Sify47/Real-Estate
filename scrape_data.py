# scrape_data.py
import pandas as pd
import requests
import numpy as np
from bs4 import BeautifulSoup
import time
from datetime import datetime
import os
import sys


def scrape_propertyfinder_page(page_url):
    """Ø¯Ø§Ù„Ø© Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† ØµÙØ­Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ PropertyFinder"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }

    try:
        response = requests.get(page_url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ØµÙØ­Ø© PropertyFinder {page_url}: {e}")
        return []

    def text_or_none(selector, parent):
        el = parent.select_one(selector)
        return el.get_text(strip=True) if el else None

    property_cards = soup.select("ul.styles_desktop_container__V85pq li")
    properties = []

    for card in property_cards:
        try:
            a = card.select_one("a.styles-module_property-card__link__r--GK")
            link = (
                f"https://www.propertyfinder.eg{a.get('href')}"
                if a and a.get("href")
                else None
            )

            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø±
            price_element = card.select_one("div.styles-module_content__price__TBYWv p")
            price = price_element.get_text(strip=True) if price_element else None

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¹Ø± Ù…Ø¨Ø§Ø´Ø±Ø© Ù‡Ù†Ø§
            if price:
                price = (
                    price.replace("EGP", "").replace(",", "").replace(" ", "").strip()
                )

            title = text_or_none("h3.styles-module_content__title__pLLTh", card)
            type_ = text_or_none(
                "p.styles-module_content__property-type__qxCMa span", card
            )

            # Ø§Ø³ØªØ®Ø¯Ø§Ù… data-testid Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ÙˆØ§ØµÙØ§Øª
            bedrooms = text_or_none('[data-testid="property-card-spec-bedroom"]', card)
            bathrooms = text_or_none(
                '[data-testid="property-card-spec-bathroom"]', card
            )

            # ØªØµØ­ÙŠØ­ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø§Ø­Ø©
            area_raw = text_or_none('[data-testid="property-card-spec-area"]', card)
            if area_raw:
                # Ø¥Ø²Ø§Ù„Ø© "mÂ²" ÙˆØ§Ù„Ø­Ø±ÙˆÙ ØºÙŠØ± Ø±Ù‚Ù…ÙŠØ©
                area = "".join(filter(str.isdigit, area_raw.replace(",", "")))
            else:
                area = None

            location = text_or_none("p.styles-module_content__location__yBL3r", card)

            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Down Payment
            down_payment_element = card.select_one("div.tag-module_tag__jFU3w")
            if down_payment_element:
                Down_Payment = down_payment_element.get_text(strip=True)
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ
                Down_Payment = Down_Payment.replace("EGP", "").replace(",", "").strip()
            else:
                Down_Payment = "0"

            properties.append(
                {
                    "PropertyType": type_,
                    "Link": link,
                    "Title": title,
                    "Price": price,
                    "Location": location,
                    "Area": area,
                    "Bedrooms": bedrooms,
                    "Bathrooms": bathrooms,
                    "Down_Payment": Down_Payment,
                    "Payment_Method": "Installments" if Down_Payment != "0" else "Cash",
                }
            )
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ø±Ø¯ PropertyFinder: {e}")
            continue

    return properties


def scrape_bayut_page(page_url):
    """Ø¯Ø§Ù„Ø© Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† ØµÙØ­Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙŠ Bayut"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
    }

    try:
        response = requests.get(page_url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, "html.parser")
    except Exception as e:
        print(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ ØµÙØ­Ø© Bayut {page_url}: {e}")
        return []

    def text_or_none(selector, parent):
        el = parent.select_one(selector)
        return el.get_text(strip=True) if el else None

    property_cards = soup.select("ul._172b35d1 li")
    properties = []

    for card in property_cards:
        try:
            a = card.select_one("a._8969fafd")
            link = (
                f"https://www.bayut.eg{a.get('href')}" if a and a.get("href") else None
            )

            price = text_or_none(
                "h4.afdad5da._71366de7 span.eff033a6", card
            ) or text_or_none("span.eff033a6", card)
            title = text_or_none("h2._34c51035", card)

            spans = card.select("span._3002c6fb")
            type_ = spans[0].get_text(strip=True) if len(spans) > 0 else None
            bedrooms = spans[1].get_text(strip=True) if len(spans) > 1 else None
            bathrooms = spans[2].get_text(strip=True) if len(spans) > 2 else None

            location = text_or_none("h3._51c6b1ca", card)
            d = text_or_none("span.fd7ade6e", card)

            area_raw = text_or_none("h4._60820635._07b5f28e", card) or text_or_none(
                "h4", card
            )
            if area_raw and len(area_raw) > 6:
                area = area_raw[:-6]
            else:
                area = area_raw

            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¹Ø±
            if price:
                price = price.replace(",", "").replace("EGP", "").strip()

            # ØªÙ†Ø¸ÙŠÙ Down Payment
            if d:
                Down_Payment = d.replace("EGP", "").replace(",", "").strip()
                Payment_Method = (
                    "Installments"
                    if Down_Payment != "0" and Down_Payment != ""
                    else "Cash"
                )
            else:
                Down_Payment = "0"
                Payment_Method = "Cash"

            properties.append(
                {
                    "PropertyType": type_,
                    "Link": link,
                    "Title": title,
                    "Price": price,
                    "Location": location,
                    "Area": area,
                    "Bedrooms": bedrooms,
                    "Bathrooms": bathrooms,
                    "Down_Payment": Down_Payment,
                    "Payment_Method": Payment_Method,
                }
            )
        except Exception as e:
            print(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙƒØ§Ø±Ø¯ Bayut: {e}")
            continue

    return properties


def scrape_all_propertyfinder_pages(base_url, max_pages=3):
    """Ø¯Ø§Ù„Ø© Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ ØµÙØ­Ø§Øª PropertyFinder"""
    all_properties = []

    # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
    print(f"Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PropertyFinder Ø§Ù„ØµÙØ­Ø© 1...")
    page1_properties = scrape_propertyfinder_page(base_url)
    all_properties.extend(page1_properties)
    print(f"ØªÙ… Ø¬Ù…Ø¹ {len(page1_properties)} Ø¹Ù‚Ø§Ø± Ù…Ù† PropertyFinder Ø§Ù„ØµÙØ­Ø© 1")

    # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©
    for page_num in range(2, max_pages + 1):
        page_url = f"{base_url}page={page_num}"
        print(f"Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PropertyFinder Ø§Ù„ØµÙØ­Ø© {page_num}...")

        properties = scrape_propertyfinder_page(page_url)

        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©ØŒ ØªÙˆÙ‚Ù
        if not properties:
            print(
                f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù‚Ø§Ø±Ø§Øª ÙÙŠ PropertyFinder Ø§Ù„ØµÙØ­Ø© {page_num}. Ø§Ù„ØªÙˆÙ‚Ù..."
            )
            break

        all_properties.extend(properties)
        print(f"ØªÙ… Ø¬Ù…Ø¹ {len(properties)} Ø¹Ù‚Ø§Ø± Ù…Ù† PropertyFinder Ø§Ù„ØµÙØ­Ø© {page_num}")

        # ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ù„ØªØ¬Ù†Ø¨ Ø­Ø¸Ø± IP
        time.sleep(1)

    return all_properties


def scrape_all_bayut_pages(base_url, max_pages=40):
    """Ø¯Ø§Ù„Ø© Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø¬Ù…ÙŠØ¹ ØµÙØ­Ø§Øª Bayut"""
    all_properties = []

    # Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰
    print(f"Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Bayut Ø§Ù„ØµÙØ­Ø© 1...")
    page1_properties = scrape_bayut_page(base_url)
    all_properties.extend(page1_properties)
    print(f"ØªÙ… Ø¬Ù…Ø¹ {len(page1_properties)} Ø¹Ù‚Ø§Ø± Ù…Ù† Bayut Ø§Ù„ØµÙØ­Ø© 1")

    # Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©
    for page_num in range(2, max_pages + 1):
        page_url = f"{base_url.rstrip('/')}/page-{page_num}/"
        print(f"Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Bayut Ø§Ù„ØµÙØ­Ø© {page_num}...")

        properties = scrape_bayut_page(page_url)

        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¹Ù‚Ø§Ø±Ø§Øª ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙØ­Ø©ØŒ ØªÙˆÙ‚Ù
        if not properties:
            print(f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù‚Ø§Ø±Ø§Øª ÙÙŠ Bayut Ø§Ù„ØµÙØ­Ø© {page_num}. Ø§Ù„ØªÙˆÙ‚Ù...")
            break

        all_properties.extend(properties)
        print(f"ØªÙ… Ø¬Ù…Ø¹ {len(properties)} Ø¹Ù‚Ø§Ø± Ù…Ù† Bayut Ø§Ù„ØµÙØ­Ø© {page_num}")

        # ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ù„ØªØ¬Ù†Ø¨ Ø­Ø¸Ø± IP
        time.sleep(1)

    return all_properties


def clean_data_step1(df_clean):
    """Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ"""
    # Ensure 'Location' exists
    if "Location" not in df_clean.columns:
        return df_clean

    # Split Location into parts and concatenate
    df_split = df_clean["Location"].str.split(",", expand=True).add_prefix("Location_")
    df_clean = pd.concat([df_clean.drop(columns=["Location"]), df_split], axis=1)

    # Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    num_columns = df_split.shape[1]

    # Ø¯Ø§ÙŠÙ…Ø§Ù‹ Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ Ø¬Ø²Ø¡ ÙƒÙ€ Location
    if "Location_0" in df_clean.columns:
        location_value = df_split["Location_0"].str.strip()
        df_clean["Location"] = location_value
    else:
        df_clean["Location"] = np.nan

    # ØªØ­Ø¯ÙŠØ¯ State Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡
    if num_columns >= 3:
        # Ø­Ø§Ù„Ø© 3 Ø£Ø¬Ø²Ø§Ø¡: Ù†Ø£Ø®Ø° Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ
        if "Location_1" in df_clean.columns:
            df_clean["State"] = df_split["Location_1"].str.strip()
        else:
            df_clean["State"] = df_clean["Location"]  # Ø¥Ø°Ø§ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ù†Ø§Ø®Ø¯ Location
    elif num_columns >= 2:
        # Ø­Ø§Ù„Ø© Ø¬Ø²Ø¦ÙŠÙ†: State ØªÙƒÙˆÙ† Ù†ÙØ³ Location
        df_clean["State"] = df_clean["Location"]
    elif num_columns >= 1:
        # Ø­Ø§Ù„Ø© Ø¬Ø²Ø¡ ÙˆØ§Ø­Ø¯: State ØªÙƒÙˆÙ† Ù†ÙØ³ Location
        df_clean["State"] = df_clean["Location"]
    else:
        df_clean["State"] = np.nan

    # Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    for col in ["Location_0", "Location_1", "Location_2"]:
        if col in df_clean.columns:
            df_clean = df_clean.drop(columns=[col])

    # Normalize text values
    if "State" in df_clean.columns:
        mask_state = df_clean["State"].notna()
        df_clean.loc[mask_state, "State"] = df_clean.loc[
            mask_state, "State"
        ].str.replace("Saba Pasha", "Saba Basha", case=False, regex=False)
        df_clean.loc[mask_state, "State"] = df_clean.loc[
            mask_state, "State"
        ].str.replace("Borg al-Arab", "Borg El Arab", case=False, regex=False)
        df_clean.loc[mask_state, "State"] = df_clean.loc[
            mask_state, "State"
        ].str.replace("Smoha", "Smouha", case=False, regex=False)
        df_clean.loc[mask_state, "State"] = df_clean.loc[
            mask_state, "State"
        ].str.replace("Alex West", "Agami", case=False, regex=False)
        df_clean.loc[mask_state, "State"] = df_clean.loc[
            mask_state, "State"
        ].str.replace("Borg El Arab City", "Borg El Arab", case=False, regex=False)

    if "Location" in df_clean.columns:
        mask_loc = df_clean["Location"].notna()
        df_clean.loc[mask_loc, "Location"] = df_clean.loc[
            mask_loc, "Location"
        ].str.replace("Smoha", "Smouha", case=False, regex=False)
        df.loc[mask_loc, "Location"] = df.loc[
                    mask_loc, "Location"
                ].str.replace("Palm Hills Alexandria", "Palm Hills", case=False, regex=False)
        df.loc[mask_loc, "Location"] = df.loc[
                    mask_loc, "Location"
                ].str.replace("Borg al-Arab", "Borg El Arab", case=False, regex=False)
        df.loc[df["Location"] == "Palm Hills", "State"] = "Palm Hills"
    df_clean["State"] = df_clean["State"].str.strip()
    mask = df_clean["State"].str.contains("Alexandria", case=False, na=False)
    mask1 = df_clean["State"].str.contains("Hay Sharq", case=False, na=False)
    df_clean.loc[mask, "State"] = df_clean.loc[mask, "Location"]
    df_clean.loc[mask1, "State"] = df_clean.loc[mask1, "Location"]
    df_clean["State"] = df_clean["State"].fillna(df_clean["Location"])
    return df_clean


def clean_data_step2(df_clean):
    """Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ"""
    try:
        # 1. ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ© Ù‡ÙŠ string dtype
        text_columns = [
            "Location",
            "State",
            "Bedrooms",
            "Bathrooms",
            "Down_Payment",
            "Price",
            "Area",
            "PropertyType",
            "Title",
        ]
        for col in text_columns:
            if col in df_clean.columns:
                df_clean[col] = df_clean[col].astype("string")

        # 2. ØªÙ†Ø¸ÙŠÙ ÙˆØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†ØµÙˆØµ
        if "State" in df_clean.columns:
            df_clean["State"] = df_clean["State"].str.replace(
                "Saba Pasha", "Saba Basha", case=False, regex=False
            )
            df_clean["State"] = df_clean["State"].str.replace(
                "Borg al-Arab", "Borg El Arab", case=False, regex=False
            )
            df_clean["State"] = df_clean["State"].str.replace(
                "Smoha", "Smouha", case=False, regex=False
            )

        if "Location" in df_clean.columns:
            df_clean["Location"] = df_clean["Location"].str.replace(
                "Smoha", "Smouha", case=False, regex=False
            )

        # 3. ØªÙ†Ø¸ÙŠÙ Price
        if "Price" in df_clean.columns:
            df_clean["Price"] = df_clean["Price"].str.replace(",", "", regex=False)
            df_clean["Price"] = df_clean["Price"].str.replace("EGP", "", regex=False)
            df_clean["Price"] = pd.to_numeric(df_clean["Price"], errors="coerce")

        # 4. ØªÙ†Ø¸ÙŠÙ Area
        if "Area" in df_clean.columns:
            df_clean["Area"] = df_clean["Area"].str.replace(",", "", regex=False)
            df_clean["Area"] = df_clean["Area"].str.replace("mÂ²", "", regex=False)
            df_clean["Area"] = df_clean["Area"].str.replace("m", "", regex=False)
            df_clean["Area"] = pd.to_numeric(df_clean["Area"], errors="coerce")

        # 5. ØªÙ†Ø¸ÙŠÙ Bedrooms
        if "Bedrooms" in df_clean.columns:
            df_clean["Bedrooms"] = df_clean["Bedrooms"].str.replace(
                "+ Maid", "", case=False, regex=False
            )
            df_clean["Bedrooms"] = df_clean["Bedrooms"].str.replace(
                "+", "", case=False, regex=False
            )
            df_clean["Bedrooms"] = df_clean["Bedrooms"].str.replace(
                "studio", "1", case=False, regex=False
            )
            df_clean["Bedrooms"] = df_clean["Bedrooms"].str.replace(
                ".0", "", case=False, regex=False
            )
            df_clean["Bedrooms"] = pd.to_numeric(df_clean["Bedrooms"], errors="coerce")

        # 6. ØªÙ†Ø¸ÙŠÙ Bathrooms
        if "Bathrooms" in df_clean.columns:
            df_clean["Bathrooms"] = df_clean["Bathrooms"].str.replace(
                "+", "", case=False, regex=False
            )
            df_clean["Bathrooms"] = df_clean["Bathrooms"].str.replace(
                ".0", "", case=False, regex=False
            )
            df_clean["Bathrooms"] = pd.to_numeric(
                df_clean["Bathrooms"], errors="coerce"
            )

        # 7. ØªÙ†Ø¸ÙŠÙ Down_Payment
        if "Down_Payment" in df_clean.columns:
            df_clean["Down_Payment"] = df_clean["Down_Payment"].astype(str)
            df_clean["Down_Payment"] = df_clean["Down_Payment"].str.replace(
                " EGP", "", case=False, regex=False
            )
            df_clean["Down_Payment"] = df_clean["Down_Payment"].str.replace(
                "EGP", "", case=False, regex=False
            )
            df_clean["Down_Payment"] = df_clean["Down_Payment"].str.replace(
                "0% Down Payment", "0", case=False, regex=False
            )
            df_clean["Down_Payment"] = df_clean["Down_Payment"].str.replace(
                " 50 monthly / 1 year", "0", case=False, regex=False
            )

            for years in range(1, 13):
                pattern = (
                    f"monthly / {years} years" if years > 1 else "monthly / 1 year"
                )
                df_clean["Down_Payment"] = df_clean["Down_Payment"].str.replace(
                    pattern, "", case=False, regex=False
                )

            df_clean["Down_Payment"] = df_clean["Down_Payment"].str.replace(
                ",", "", regex=False
            )
            df_clean["Down_Payment"] = pd.to_numeric(
                df_clean["Down_Payment"], errors="coerce"
            ).fillna(0)

        # 8. Ø­Ø³Ø§Ø¨ Price_Per_M
        if "Price" in df_clean.columns and "Area" in df_clean.columns:
            mask = df_clean["Area"] > 0
            df_clean.loc[mask, "Price_Per_M"] = (
                df_clean.loc[mask, "Price"] / df_clean.loc[mask, "Area"]
            )
            df_clean["Price_Per_M"] = df_clean["Price_Per_M"].round(2)

        # 9. Ø¥Ø¶Ø§ÙØ© ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¬Ù…Ø¹

        return df_clean

    except Exception as e:
        print(f"âŒ Error in clean_data_step2: {e}")
        import traceback

        traceback.print_exc()
        return df_clean


def process_and_save_data(df_raw, output_path):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    print("ğŸ”„ Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")

    # Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù…Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    df_clean_1 = clean_data_step1(df_raw.copy())
    df1 = df_clean_1.copy()

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Down_Payment
    if "Down_Payment" in df1.columns:
        df1["Down_Payment"] = df1["Down_Payment"].fillna(0)

    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ©
    initial_count = len(df1)
    required_columns = ["Location", "State", "Price", "Area"]
    for col in required_columns:
        if col in df1.columns:
            df1 = df1[df1[col].notna() & (df1[col] != "")]

    df1.reset_index(drop=True, inplace=True)
    print(f"âœ… ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© {initial_count - len(df1)} ØµÙ ÙØ§Ø±Øº")

    # ØªÙ†Ø¸ÙŠÙ Ø¥Ø¶Ø§ÙÙŠ
    df_clean = df1.copy()
    if "State" in df_clean.columns:
        df_clean["State"] = df_clean["State"].str.strip()
    if "Location" in df_clean.columns:
        df_clean["Location"] = df_clean["Location"].str.strip()

    # Ø¥Ø¶Ø§ÙØ© Payment_Method Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
    if "Payment_Method" not in df_clean.columns:
        df_clean["Payment_Method"] = "Cash"
        if "Down_Payment" in df_clean.columns:
            mask_installments = (
                df_clean["Down_Payment"].astype(str).str.strip() != "0"
            ) & (df_clean["Down_Payment"].astype(str).str.strip() != "")
            df_clean.loc[mask_installments, "Payment_Method"] = "Installments"

    # Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© Ù…Ù† Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    df_clean = clean_data_step2(df_clean)
    df_clean = df_clean.drop(columns=["Location_4", "Location_3"])
    df_clean = df_clean.dropna()
    df_clean = df_clean.reset_index(drop=True)
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ NaN ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
    important_columns = ["Price", "Area", "Location"]
    for col in important_columns:
        if col in df_clean.columns:
            df_clean = df_clean[df_clean[col].notna()]

    # Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø©
    print("\nğŸ” Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    final_sample = df_clean[
        ["Location", "State", "Price", "Area", "Payment_Method"]
    ].head(10)
    for idx, row in final_sample.iterrows():
        print(
            f"Location: '{row['Location']}', State: '{row['State']}', "
            f"Price: {row['Price']:,.0f}, Area: {row['Area']}, Payment: {row['Payment_Method']}"
        )

    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø¥Ø°Ø§ ÙˆØ¬Ø¯Øª
    if os.path.exists(output_path):
        try:
            df_final = pd.read_csv(output_path)
            print(f"ğŸ“ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ÙˆØ¬ÙˆØ¯Ø©: {len(df_final)} Ø¹Ù‚Ø§Ø±")

            # Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df_combined = pd.concat([df_final, df_clean], ignore_index=True)

            # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø·
            if "Link" in df_combined.columns:
                initial_combined = len(df_combined)
                df_combined = df_combined.drop_duplicates(subset=["Link"], keep="last")

                df_combined = df_combined.drop(
                    columns=["Location_4", "Location_3", "Scrape_Date", "Source"],
                    errors="ignore",
                )
                df_combined = df_combined.dropna()
                df_combined = df_combined.reset_index(drop=True)
                df_combined = df_combined.astype({'Bedrooms': 'int' , 'Down_Payment': 'int' , 'Bathrooms': 'int'})
                duplicates_removed = initial_combined - len(df_combined)
                if duplicates_removed > 0:
                    print(f"ğŸ”„ ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© {duplicates_removed} Ø¹Ù‚Ø§Ø± Ù…ÙƒØ±Ø±")

            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            df_combined.to_csv(output_path, index=False)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(df_combined)} Ø¹Ù‚Ø§Ø± ÙÙŠ {output_path}")
            print(
                f"ğŸ“ˆ Ø§Ù„ØªØºÙŠÙŠØ± Ø§Ù„ØµØ§ÙÙŠ: {len(df_clean) - duplicates_removed:+d} Ø¹Ù‚Ø§Ø± Ø¬Ø¯ÙŠØ¯"
            )

        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø©/Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {e}")
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø·
            df_clean.to_csv(output_path, index=False)
            print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(df_clean)} Ø¹Ù‚Ø§Ø± ÙÙŠ {output_path} (Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯)")
    else:
        # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        df_clean.to_csv(output_path, index=False)
        print(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ {len(df_clean)} Ø¹Ù‚Ø§Ø± ÙÙŠ {output_path} (Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯)")

    return df_clean


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø¬Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ù…Ù† ÙƒÙ„Ø§ Ø§Ù„Ù…ÙˆÙ‚Ø¹ÙŠÙ†")
    print("=" * 50)
    print(f"ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    propertyfinder_url = (
        "https://www.propertyfinder.eg/en/search?l=30754&c=1&fu=0&ob=mr&"
    )
    bayut_url = "https://www.bayut.eg/en/alexandria/properties-for-sale/"

    propertyfinder_pages = 40
    bayut_pages = 40
    output_path = "Final1.csv"

    # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PropertyFinder
    print(f"\nğŸ“¥ Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PropertyFinder ({propertyfinder_pages} ØµÙØ­Ø§Øª)...")
    propertyfinder_properties = scrape_all_propertyfinder_pages(
        propertyfinder_url, max_pages=propertyfinder_pages
    )
    print(f"âœ… ØªÙ… Ø¬Ù…Ø¹ {len(propertyfinder_properties)} Ø¹Ù‚Ø§Ø± Ù…Ù† PropertyFinder")

    # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Bayut
    print(f"\nğŸ“¥ Ø¬Ø§Ø±ÙŠ Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Bayut ({bayut_pages} ØµÙØ­Ø§Øª)...")
    bayut_properties = scrape_all_bayut_pages(bayut_url, max_pages=bayut_pages)
    print(f"âœ… ØªÙ… Ø¬Ù…Ø¹ {len(bayut_properties)} Ø¹Ù‚Ø§Ø± Ù…Ù† Bayut")

    # Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    all_properties = propertyfinder_properties + bayut_properties

    if not all_properties:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø¬Ù…Ø¹ Ø£ÙŠ Ø¹Ù‚Ø§Ø±Ø§Øª!")
        return False

    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ DataFrame
    df_raw = pd.DataFrame(all_properties)
    print(f"\nğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©: {len(df_raw)} Ø¹Ù‚Ø§Ø±")
    print(f"  - PropertyFinder: {len(propertyfinder_properties)} Ø¹Ù‚Ø§Ø±")
    print(f"  - Bayut: {len(bayut_properties)} Ø¹Ù‚Ø§Ø±")

    # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df_final = process_and_save_data(df_raw, output_path)

    # Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ
    print("\n" + "=" * 50)
    print("ğŸ“‹ Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©:")
    print("=" * 50)
    print(f"Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©: {len(df_raw)}")
    print(f"Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {len(df_final)}")

    if not df_final.empty:
        if "Price" in df_final.columns:
            print(f"\nğŸ’° Ù…ØªÙˆØ³Ø· Ø§Ù„Ø³Ø¹Ø±: {df_final['Price'].mean():,.0f} EGP")

        if "Payment_Method" in df_final.columns:
            print(f"\nğŸ’³ Ø·Ø±Ù‚ Ø§Ù„Ø¯ÙØ¹:")
            payment_counts = df_final["Payment_Method"].value_counts()
            for method, count in payment_counts.items():
                print(f"  - {method}: {count}")

    print("=" * 50)
    print("âœ… Ø§ÙƒØªÙ…Ù„Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø¬Ù…Ø¹ Ø¨Ù†Ø¬Ø§Ø­!")

    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    if not df_final.empty and len(df_final) > 0:
        print(f"\nğŸ“ˆ Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©:")
        print(f"  - Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ÙØ±ÙŠØ¯Ø©: {df_final['Location'].nunique()}")
        if "Bedrooms" in df_final.columns:
            print(f"  - Ù…ØªÙˆØ³Ø· Ø¹Ø¯Ø¯ Ø§Ù„ØºØ±Ù: {df_final['Bedrooms'].mean():.1f}")
        if "Area" in df_final.columns:
            print(f"  - Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…Ø³Ø§Ø­Ø©: {df_final['Area'].mean():.0f} mÂ²")

    return True


if __name__ == "__main__":
    try:
        success = main()
        sys.exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)
