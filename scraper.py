import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime

def scrape_bayut_simple():
    """Ø¯Ø§Ù„Ø© Ù…Ø¨Ø³Ø·Ø© Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Bayut"""
    
    print("ğŸ” Starting data collection from Bayut...")
    
    properties = []
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # Ø¬Ù…Ø¹ Ù…Ù† 3 ØµÙØ­Ø§Øª ÙÙ‚Ø· Ù„Ù„Ø³Ø±Ø¹Ø©
    for page in range(1, 4):
        try:
            if page == 1:
                url = "https://www.bayut.eg/en/alexandria/properties-for-sale/"
            else:
                url = f"https://www.bayut.eg/en/alexandria/properties-for-sale/page-{page}/"
            
            print(f"ğŸ“„ Collecting page {page}...")
            
            response = requests.get(url, headers=headers)
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø¹Ù‚Ø§Ø±Ø§Øª
            cards = soup.find_all('li', {'data-testid': 'listing-card'})
            
            for card in cards:
                try:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
                    title_elem = card.find('h2')
                    title = title_elem.text.strip() if title_elem else "N/A"
                    
                    price_elem = card.find('span', class_='ef033a6')
                    price = price_elem.text.strip() if price_elem else "N/A"
                    
                    location_elem = card.find('h3')
                    location = location_elem.text.strip() if location_elem else "N/A"
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø³Ø¹Ø±
                    if price != "N/A":
                        price = price.replace('EGP', '').replace(',', '').strip()
                        try:
                            price = float(price)
                        except:
                            price = 0
                    
                    # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ù‚Ø§Ø¦Ù…Ø©
                    properties.append({
                        'Title': title,
                        'Price': price if price != "N/A" else 0,
                        'Location': location,
                        'State': 'Alexandria',  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                        'PropertyType': 'Apartment',  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                        'Bedrooms': 2,  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                        'Bathrooms': 1,  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                        'Area': 100,  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                        'Payment_Method': 'Cash',  # Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹
                        'Scraped_Date': datetime.now().strftime('%Y-%m-%d'),
                        'Source': 'Bayut'
                    })
                    
                except Exception as e:
                    continue
            
            time.sleep(1)  # ØªØ£Ø®ÙŠØ± Ø¨ÙŠÙ† Ø§Ù„ØµÙØ­Ø§Øª
            
        except Exception as e:
            print(f"âŒ Error on page {page}: {e}")
            continue
    
    print(f"âœ… Collected {len(properties)} properties")
    return pd.DataFrame(properties)

def run_scraping():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ù€ Scraping"""
    
    print("ğŸš€ Starting scraping process...")
    
    # Ø¬Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Bayut
    df_bayut = scrape_bayut_simple()
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    df_clean = clean_data(df_bayut)
    
    print(f"ğŸ¯ Final data: {len(df_clean)} properties")
    
    return df_clean

def clean_data(df):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""
    
    if df.empty:
        return df
    
    # Ù†Ø³Ø®Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    df_clean = df.copy()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„ÙØ§Ø±ØºØ© ÙÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
    df_clean = df_clean.dropna(subset=['Title', 'Price', 'Location'])
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    df_clean = df_clean.drop_duplicates(subset=['Title', 'Location'])
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹
    df_clean['Price'] = pd.to_numeric(df_clean['Price'], errors='coerce')
    df_clean['Area'] = pd.to_numeric(df_clean['Area'], errors='coerce')
    df_clean['Bedrooms'] = pd.to_numeric(df_clean['Bedrooms'], errors='coerce')
    df_clean['Bathrooms'] = pd.to_numeric(df_clean['Bathrooms'], errors='coerce')
    
    # ØªØ¹Ø¨Ø¦Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©
    df_clean = df_clean.fillna({
        'PropertyType': 'Unknown',
        'Bedrooms': 0,
        'Bathrooms': 0,
        'Area': 0,
        'Payment_Method': 'Unknown'
    })
    
    return df_clean

if __name__ == "__main__":
    # Ù„Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©
    df = run_scraping()
    print(df.head())
